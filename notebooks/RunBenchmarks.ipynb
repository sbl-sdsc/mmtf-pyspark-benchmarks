{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark for Reading and Datamining PDB Structures with mmtf-pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from mmtfPyspark.io import mmtfReader\n",
    "from mmtfPyspark.interactions import InteractionExtractor, InteractionFilter\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the benchmark\n",
    "Set the path to the MMTF Hadoop Sequence file. Here we retrieve the value of the environment variable MMTF_FULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = mmtfReader.get_mmtf_full_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify a list with the number of cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cores = [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create results directory\n",
    "results_dir = '../results'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Benchmark\n",
    "Benchmarks reading an MMTF Hadoop Sequence File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(path, num_core):\n",
    "    spark = SparkSession.builder.master(\"local[\" + str(num_cores) + \"]\").appName(\"Read\").getOrCreate()\n",
    "    structures = mmtfReader.read_sequence_file(path, fraction=0.01)\n",
    "    count = structures.count()\n",
    "    spark.stop()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_read = pd.DataFrame(columns=('cores', 'read'))\n",
    "\n",
    "for num_cores in cores:\n",
    "    start = time.time()\n",
    "    count = read(path, num_cores)\n",
    "    end = time.time()\n",
    "    print('read, cores:', num_cores, 'time:', end-start, 'seconds')\n",
    "    df_read = df_read.append([{'cores':num_cores, 'read': end-start, 'count': count}], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.to_csv(os.path.join(results_dir, 'read.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactions Benchmark\n",
    "This benchmark finds all zinc interactions in PDB structures. Structures with multiple models, e.g., NMR structures are excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactions(path, num_core):\n",
    "    spark = SparkSession.builder.master(\"local[\" + str(num_cores) + \"]\").appName(\"Interactions\").getOrCreate()\n",
    "    structures = mmtfReader.read_sequence_file(path, fraction=0.05)\n",
    "    structures = structures.filter(lambda s: s[1].num_models == 1)\n",
    "                               \n",
    "    interaction_filter = InteractionFilter()\n",
    "    interaction_filter.set_target_elements(False, ['C','H','P'])\n",
    "    interaction_filter.set_query_elements(True, ['Zn'])\n",
    "    interaction_filter.set_distance_cutoff(3.0)\n",
    "\n",
    "    interactions = InteractionExtractor().get_ligand_polymer_interactions(structures, interaction_filter)\n",
    "    count = interactions.count()\n",
    "\n",
    "    spark.stop()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_interactions = pd.DataFrame(columns=('cores', 'interactions'))\n",
    "\n",
    "for num_cores in cores:\n",
    "    start = time.time()\n",
    "    count = interactions(path, num_cores)\n",
    "    end = time.time()\n",
    "    print('interactions, cores:', num_cores, 'time:', end-start, 'seconds')\n",
    "    df_interactions = df_interactions.append([{'cores':num_cores, 'interactions': end-start, 'count': count}], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interactions.to_csv(os.path.join(results_dir, 'interactions.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saltbridges Benchmark\n",
    "This benchmark finds salt bridges in protein structures. Structures with multiple models, e.g., NMR structures are excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saltbridges(path, num_core):\n",
    "    spark = SparkSession.builder.master(\"local[\" + str(num_cores) + \"]\").appName(\"Saltbridges\").getOrCreate()\n",
    "    structures = mmtfReader.read_sequence_file(path, fraction=0.05)\n",
    "    structures = structures.filter(lambda s: s[1].num_models == 1)\n",
    "                               \n",
    "    salt_bridge = InteractionFilter(distanceCutoff=3.5)\n",
    "    salt_bridge.set_query_groups(True, ['ASP', 'GLU'])\n",
    "    salt_bridge.set_query_atom_names(True, ['OD1', 'OD2', 'OE1', 'OE2'])\n",
    "    salt_bridge.set_target_groups(True, ['ARG', 'LYS', 'HIS'])\n",
    "    salt_bridge.set_target_atom_names(True, ['NH1', 'NH2', 'NZ', 'ND1', 'NE2'])\n",
    "\n",
    "    interactions = InteractionExtractor.get_polymer_interactions(structures, salt_bridge)\n",
    "    count = interactions.count()\n",
    "\n",
    "    spark.stop()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_saltbridges = pd.DataFrame(columns=('cores', 'saltbridges'))\n",
    "\n",
    "for num_cores in cores:\n",
    "    start = time.time()\n",
    "    count = saltbridges(path, num_cores)\n",
    "    end = time.time()\n",
    "    print('saltbridges, cores:', num_cores, 'time:', end-start, 'seconds')\n",
    "    df_saltbridges = df_saltbridges.append([{'cores':num_cores, 'saltbridges': end-start, 'count': count}], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_saltbridges.to_csv(os.path.join(results_dir, 'saltbridges.csv'), index=False)\n",
    "df_saltbridges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
